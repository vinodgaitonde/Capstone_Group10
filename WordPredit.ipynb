{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl71YHSARd0wg6manaGXN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinodgaitonde/ProjIdeas/blob/main/WordPredit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required packages"
      ],
      "metadata": {
        "id": "xOLmTs6jWGMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "metadata": {
        "id": "QzSRbwR3VHco"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "id": "3w0d5Q6lWqVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./sample_data/1661-split.txt', 'r') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "print(text[:100])"
      ],
      "metadata": {
        "id": "AzmhPbNzWtpT",
        "outputId": "ebe9a185-f137-4f38-ee89-9d0c3cd85075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 581888\n",
            "﻿\n",
            "project gutenberg's the adventures of sherlock holmes, by arthur conan doyle\n",
            "\n",
            "this ebook is for th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset"
      ],
      "metadata": {
        "id": "Gd99sSh0m6Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)\n",
        "\n",
        "print(len(words))\n",
        "print(words[:100])"
      ],
      "metadata": {
        "id": "AU1eSREmm9Dy",
        "outputId": "2edcb639-b9ed-415e-bb9b-2a7272aa30cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109226\n",
            "['project', 'gutenberg', 's', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan', 'doyle', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'title', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'author', 'arthur', 'conan', 'doyle', 'release', 'date', 'november', '29', '2002', 'ebook', '1661', 'last', 'updated', 'may', '20', '2019', 'language', 'english', 'character', 'set', 'encoding', 'utf', '8', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'produced']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unique Words"
      ],
      "metadata": {
        "id": "VwHZ9N3Bn7dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
        "\n",
        "print(unique_words)"
      ],
      "metadata": {
        "id": "ITv6801En_yi",
        "outputId": "abd1b863-6bfc-434d-eada-37f40553ecc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' '000' '1' ... 'zigzag' 'zip' 'œuvre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Word length which will represent the number of previous words that will determine our next word.\n",
        "Define prev words to keep five previous words and their corresponding next words in the list of next words."
      ],
      "metadata": {
        "id": "_xlNy_QhpSQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_LENGTH = 5\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print(prev_words[0])\n",
        "print(next_words[0])"
      ],
      "metadata": {
        "id": "NLui-qGTpSqh",
        "outputId": "c2144f85-6868-4fdb-d508-c92d757c0ff2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['project', 'gutenberg', 's', 'the', 'adventures']\n",
            "of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create two numpy arrays X for storing the features and Y for storing its corresponding label."
      ],
      "metadata": {
        "id": "q5G73c-EroZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1\n",
        "\n",
        "print(X[0][0])"
      ],
      "metadata": {
        "id": "J2TMnesqrwL2",
        "outputId": "ebca299f-9d4a-4b50-bfd3-40df9f4b729e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False ... False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Recurrent Neural network"
      ],
      "metadata": {
        "id": "xW5nNehOsVYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Recurrent Neural Networks for next word prediction model.\n",
        "Here we will use the LSTM model, which is a very powerful RNN"
      ],
      "metadata": {
        "id": "z50FvNV1sXyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "DQaqHr2qsjl_",
        "outputId": "35fc02db-9d83-423d-f749-962cb0a82dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Next Word Prediction Model"
      ],
      "metadata": {
        "id": "Bz6oGe32uF55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=45, shuffle=True).history"
      ],
      "metadata": {
        "id": "G9hjudaJuHYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}